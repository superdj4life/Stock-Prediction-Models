{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "tf.compat.v1.random.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>778.200012</td>\n",
       "      <td>781.650024</td>\n",
       "      <td>763.450012</td>\n",
       "      <td>768.700012</td>\n",
       "      <td>768.700012</td>\n",
       "      <td>1872400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>767.250000</td>\n",
       "      <td>769.950012</td>\n",
       "      <td>759.030029</td>\n",
       "      <td>762.130005</td>\n",
       "      <td>762.130005</td>\n",
       "      <td>1943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>750.659973</td>\n",
       "      <td>770.359985</td>\n",
       "      <td>750.560974</td>\n",
       "      <td>762.020020</td>\n",
       "      <td>762.020020</td>\n",
       "      <td>2134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>774.500000</td>\n",
       "      <td>785.190002</td>\n",
       "      <td>772.549988</td>\n",
       "      <td>782.520020</td>\n",
       "      <td>782.520020</td>\n",
       "      <td>1585100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>783.400024</td>\n",
       "      <td>795.632996</td>\n",
       "      <td>780.190002</td>\n",
       "      <td>790.510010</td>\n",
       "      <td>790.510010</td>\n",
       "      <td>1350800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close   \n",
       "0  2016-11-02  778.200012  781.650024  763.450012  768.700012  768.700012  \\\n",
       "1  2016-11-03  767.250000  769.950012  759.030029  762.130005  762.130005   \n",
       "2  2016-11-04  750.659973  770.359985  750.560974  762.020020  762.020020   \n",
       "3  2016-11-07  774.500000  785.190002  772.549988  782.520020  782.520020   \n",
       "4  2016-11-08  783.400024  795.632996  780.190002  790.510010  790.510010   \n",
       "\n",
       "    Volume  \n",
       "0  1872400  \n",
       "1  1943200  \n",
       "2  2134800  \n",
       "3  1585100  \n",
       "4  1350800  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/Files/GOOG-year.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.160459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.112708\n",
       "1  0.090008\n",
       "2  0.089628\n",
       "3  0.160459\n",
       "4  0.188066"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = MinMaxScaler().fit(df.iloc[:, 4:5].astype('float32')) # Close index\n",
    "df_log = minmax.transform(df.iloc[:, 4:5].astype('float32')) # Close index\n",
    "df_log = pd.DataFrame(df_log)\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test\n",
    "\n",
    "I will cut the dataset to train and test datasets,\n",
    "\n",
    "1. Train dataset derived from starting timestamp until last 30 days\n",
    "2. Test dataset derived from last 30 days until end of the dataset\n",
    "\n",
    "So we will let the model do forecasting based on last 30 days, and we will going to repeat the experiment for 10 times. You can increase it locally if you want, and tuning parameters will help you by a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m test_size \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[0;32m      2\u001b[0m simulation_size \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df_train \u001b[39m=\u001b[39m df_log\u001b[39m.\u001b[39miloc[:\u001b[39m-\u001b[39mtest_size]\n\u001b[0;32m      5\u001b[0m df_test \u001b[39m=\u001b[39m df_log\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39mtest_size:]\n\u001b[0;32m      6\u001b[0m df\u001b[39m.\u001b[39mshape, df_train\u001b[39m.\u001b[39mshape, df_test\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_log' is not defined"
     ]
    }
   ],
   "source": [
    "test_size = 30\n",
    "simulation_size = 10\n",
    "\n",
    "df_train = df_log.iloc[:-test_size]\n",
    "df_test = df_log.iloc[-test_size:]\n",
    "df.shape, df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "        \n",
    "        with tf.variable_scope('forward', reuse = False):\n",
    "            rnn_cells_forward = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "                state_is_tuple = False,\n",
    "            )\n",
    "            self.X_forward = tf.placeholder(tf.float32, (None, None, size))\n",
    "            drop_forward = tf.contrib.rnn.DropoutWrapper(\n",
    "                rnn_cells_forward, output_keep_prob = forget_bias\n",
    "            )\n",
    "            self.hidden_layer_forward = tf.placeholder(\n",
    "                tf.float32, (None, num_layers * 2 * size_layer)\n",
    "            )\n",
    "            self.outputs_forward, self.last_state_forward = tf.nn.dynamic_rnn(\n",
    "                drop_forward,\n",
    "                self.X_forward,\n",
    "                initial_state = self.hidden_layer_forward,\n",
    "                dtype = tf.float32,\n",
    "            )\n",
    "\n",
    "        with tf.variable_scope('backward', reuse = False):\n",
    "            rnn_cells_backward = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "                state_is_tuple = False,\n",
    "            )\n",
    "            self.X_backward = tf.placeholder(tf.float32, (None, None, size))\n",
    "            drop_backward = tf.contrib.rnn.DropoutWrapper(\n",
    "                rnn_cells_backward, output_keep_prob = forget_bias\n",
    "            )\n",
    "            self.hidden_layer_backward = tf.placeholder(\n",
    "                tf.float32, (None, num_layers * 2 * size_layer)\n",
    "            )\n",
    "            self.outputs_backward, self.last_state_backward = tf.nn.dynamic_rnn(\n",
    "                drop_backward,\n",
    "                self.X_backward,\n",
    "                initial_state = self.hidden_layer_backward,\n",
    "                dtype = tf.float32,\n",
    "            )\n",
    "\n",
    "        self.outputs = self.outputs_backward - self.outputs_forward\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "    return percentage * 100\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 300\n",
    "dropout_rate = 0.8\n",
    "future_day = test_size\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast():\n",
    "    tf.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "\n",
    "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
    "    for i in pbar:\n",
    "        init_value_forward = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        init_value_backward = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss, total_acc = [], []\n",
    "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
    "            batch_x_forward = np.expand_dims(\n",
    "                df_train.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_x_backward = np.expand_dims(\n",
    "                np.flip(df_train.iloc[k : index, :].values, axis = 0), axis = 0\n",
    "            )\n",
    "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
    "            logits, last_state_forward, last_state_backward, _, loss = sess.run(\n",
    "                [\n",
    "                    modelnn.logits,\n",
    "                    modelnn.last_state_forward,\n",
    "                    modelnn.last_state_backward,\n",
    "                    modelnn.optimizer,\n",
    "                    modelnn.cost,\n",
    "                ],\n",
    "                feed_dict = {\n",
    "                    modelnn.X_forward: batch_x_forward,\n",
    "                    modelnn.X_backward: batch_x_backward,\n",
    "                    modelnn.Y: batch_y,\n",
    "                    modelnn.hidden_layer_forward: init_value_forward,\n",
    "                    modelnn.hidden_layer_backward: init_value_backward,\n",
    "                },\n",
    "            )\n",
    "            init_value_forward = last_state_forward\n",
    "            init_value_backward = last_state_backward\n",
    "            total_loss.append(loss)\n",
    "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
    "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
    "    \n",
    "    future_day = test_size\n",
    "\n",
    "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
    "    output_predict[0] = df_train.iloc[0]\n",
    "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
    "    init_value_forward = np.zeros((1, num_layers * 2 * size_layer))\n",
    "    init_value_backward = np.zeros((1, num_layers * 2 * size_layer))\n",
    "\n",
    "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        batch_x_forward = np.expand_dims(\n",
    "        df_train.iloc[k : k + timestamp, :], axis = 0\n",
    "        )\n",
    "        batch_x_backward = np.expand_dims(\n",
    "            np.flip(df_train.iloc[k : k + timestamp, :].values, axis = 0), axis = 0\n",
    "        )\n",
    "        out_logits, last_state_forward, last_state_backward = sess.run(\n",
    "            [\n",
    "                modelnn.logits,\n",
    "                modelnn.last_state_forward,\n",
    "                modelnn.last_state_backward,\n",
    "            ],\n",
    "            feed_dict = {\n",
    "                modelnn.X_forward: batch_x_forward,\n",
    "                modelnn.X_backward: batch_x_backward,\n",
    "                modelnn.hidden_layer_forward: init_value_forward,\n",
    "                modelnn.hidden_layer_backward: init_value_backward,\n",
    "            },\n",
    "        )\n",
    "        init_value_forward = last_state_forward\n",
    "        init_value_backward = last_state_backward\n",
    "        output_predict[k + 1 : k + timestamp + 1, :] = out_logits\n",
    "\n",
    "    if upper_b != df_train.shape[0]:\n",
    "        batch_x_forward = np.expand_dims(df_train.iloc[upper_b:, :], axis = 0)\n",
    "        batch_x_backward = np.expand_dims(\n",
    "            np.flip(df_train.iloc[upper_b:, :].values, axis = 0), axis = 0\n",
    "        )\n",
    "        out_logits, last_state_forward, last_state_backward = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state_forward, modelnn.last_state_backward],\n",
    "            feed_dict = {\n",
    "                modelnn.X_forward: batch_x_forward,\n",
    "                modelnn.X_backward: batch_x_backward,\n",
    "                modelnn.hidden_layer_forward: init_value_forward,\n",
    "                modelnn.hidden_layer_backward: init_value_backward,\n",
    "            },\n",
    "        )\n",
    "        init_value_forward = last_state_forward\n",
    "        init_value_backward = last_state_backward\n",
    "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
    "        future_day -= 1\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "        \n",
    "    init_value_forward = last_state_forward\n",
    "    init_value_backward = last_state_backward\n",
    "    \n",
    "    for i in range(future_day):\n",
    "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
    "        o_f = np.flip(o, axis = 0)\n",
    "        out_logits, last_state_forward, last_state_backward = sess.run(\n",
    "            [\n",
    "                modelnn.logits,\n",
    "                modelnn.last_state_forward,\n",
    "                modelnn.last_state_backward,\n",
    "            ],\n",
    "            feed_dict = {\n",
    "                modelnn.X_forward: np.expand_dims(o, axis = 0),\n",
    "                modelnn.X_backward: np.expand_dims(o_f, axis = 0),\n",
    "                modelnn.hidden_layer_forward: init_value_forward,\n",
    "                modelnn.hidden_layer_backward: init_value_backward,\n",
    "            },\n",
    "        )\n",
    "        init_value_forward = last_state_forward\n",
    "        init_value_backward = last_state_backward\n",
    "        output_predict[-future_day + i] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    output_predict = minmax.inverse_transform(output_predict)\n",
    "    deep_future = anchor(output_predict[:, 0], 0.3)\n",
    "    \n",
    "    return deep_future[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0812 16:41:29.569112 139847292135232 deprecation.py:323] From <ipython-input-6-2e28fdecec52>:12: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0812 16:41:29.570642 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f302d208da0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:41:29.571565 139847292135232 deprecation.py:323] From <ipython-input-6-2e28fdecec52>:17: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:41:29.886489 139847292135232 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0812 16:41:29.889781 139847292135232 deprecation.py:323] From <ipython-input-6-2e28fdecec52>:30: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0812 16:41:30.079713 139847292135232 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0812 16:41:30.086595 139847292135232 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0812 16:41:30.565006 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f302d1de6d8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:41:30.647609 139847292135232 deprecation.py:323] From <ipython-input-6-2e28fdecec52>:54: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "train loop: 100%|██████████| 300/300 [01:39<00:00,  3.02it/s, acc=97.7, cost=0.00132] \n",
      "W0812 16:43:12.068012 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f3022b11fd0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:43:12.148377 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f30229e3080>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:40<00:00,  3.02it/s, acc=97.4, cost=0.00157]\n",
      "W0812 16:44:53.274921 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2fdc217b00>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:44:53.357845 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2fdc1bc0f0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:40<00:00,  2.98it/s, acc=97.3, cost=0.00171]\n",
      "W0812 16:46:35.140946 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f847c0240>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:46:35.223572 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f847c00b8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:38<00:00,  3.00it/s, acc=96.5, cost=0.00334] \n",
      "W0812 16:48:14.756632 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f843747f0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:48:14.838256 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f722b19e8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:41<00:00,  2.98it/s, acc=97.9, cost=0.00113]\n",
      "W0812 16:49:56.968556 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f6bd75b70>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:49:57.051066 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f6bd755f8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:40<00:00,  3.01it/s, acc=97.7, cost=0.00145]\n",
      "W0812 16:51:38.877053 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f6a0db3c8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:51:38.959546 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f6976aef0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:41<00:00,  2.98it/s, acc=97.3, cost=0.00172]\n",
      "W0812 16:53:21.123231 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f67bdbcc0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:53:21.205539 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f67258e10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:38<00:00,  3.06it/s, acc=97.8, cost=0.00117]\n",
      "W0812 16:55:00.356067 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f65677da0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:55:00.437367 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f65677898>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:38<00:00,  3.05it/s, acc=97.7, cost=0.00127]\n",
      "W0812 16:56:40.365346 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f628e67b8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0812 16:56:40.448274 139847292135232 rnn_cell_impl.py:893] <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f2f628e6320>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [01:40<00:00,  2.97it/s, acc=97.2, cost=0.00216]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(simulation_size):\n",
    "    print('simulation %d'%(i + 1))\n",
    "    results.append(forecast())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracies \u001b[39m=\u001b[39m [calculate_accuracy(df[\u001b[39m'\u001b[39m\u001b[39mClose\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39mtest_size:]\u001b[39m.\u001b[39mvalues, r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m results]\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize \u001b[39m=\u001b[39m (\u001b[39m15\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m no, r \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(results):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "accuracies = [calculate_accuracy(df['Close'].iloc[-test_size:].values, r) for r in results]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "for no, r in enumerate(results):\n",
    "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
    "plt.plot(df['Close'].iloc[-test_size:].values, label = 'true trend', c = 'black')\n",
    "plt.legend()\n",
    "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
